{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to the Study Wiki!  </p> <p>Our goal is to provide clear, concise, and ever\u2011evolving information about the beautiful fields of Data Anlytics, Data Science, Data Engineering, Machine Learning and Artificial Intelligence that helps all users\u2014from absolute beginners to seasoned contributors\u2014navigate this Study project.</p> <p>Why this wiki?</p> <ul> <li> <p>Centralises quality and easily accessible knowledge because most information in the internet is incomplete, unsatisfactory, dispersed and paid.</p> </li> <li> <p>Enables transparent, review\u2011driven improvements via pull requests.</p> </li> <li> <p>Scales from quick notes to full tutorials.</p> </li> </ul> <p>Feel free to fork the repo, open an issue, or submit a pull request if you spot anything to improve.</p>"},{"location":"01-Wiki-Structure/","title":"\ud83d\uddc2\ufe0f Wiki Structure","text":"<p>Below is the current layout (subject to change as the project grows):</p> <ol> <li>Introduction \u2013 Big\u2011picture overview and purpose.</li> <li>Wiki Structure \u2013 You are here: explains how pages are organised and linked.</li> <li>Topics Being Addressed \u2013 What we already cover in depth.</li> <li>Topics To Be Addressed \u2013 A public backlog of future articles or enhancements.</li> <li>What Can Be Better \u2013 Continuous\u2011improvement log and open questions.</li> </ol>"},{"location":"01-Wiki-Structure/#naming-convention","title":"Naming convention","text":"<ul> <li>Pages are prefixed with two\u2011digit indices (<code>00\u2011</code>, <code>01\u2011</code>, \u2026) to keep the sidebar logically ordered.</li> <li>Use <code>Title-Case-With-Dashes.md</code> for new pages.</li> </ul>"},{"location":"02-Topics-Being-Addressed/","title":"\u2705 Topics Being Addressed","text":"# Topic Status Last updated 1 Example Topic Stable 2025\u201107\u201103 2 Inheritance Stable 2025-07-23 3 Confusion Matrix Stable 2025-07-25 Add rows as you publish new articles. Use the template below:"},{"location":"02-Topics-Being-Addressed/#_1","title":"<p>Short summary paragraph explaining why this topic matters.</p>","text":""},{"location":"02-Topics-Being-Addressed/#in-this-section","title":"In this section","text":"<ul> <li>Bullet point 1</li> <li>Bullet point 2</li> </ul>"},{"location":"03-Topics-To-Be-Addressed/","title":"\ud83d\udee0\ufe0f Topics To Be Addressed","text":"<p>This page tracks ideas, requests, and drafts that are not yet fully documented. Think of it as an open backlog. Feel free to:</p> <ol> <li>Open an Issue \u2192 propose a topic.</li> <li>Assign yourself \u2192 if you want to draft it.</li> <li>Link the PR once ready.</li> </ol> Proposed topic Champion Target release Example: Advanced ETL Validation @username Q3\u20112025"},{"location":"04-What-Can-Be-Better/","title":"\ud83d\ude80 What Can Be Better","text":"<p>Continuous improvement ideas\u2014design, usability, coverage, tooling.</p>"},{"location":"04-What-Can-Be-Better/#open-suggestions","title":"Open suggestions","text":"<ul> <li>[ ] Example: Add full\u2011text search synonym support.</li> <li>[ ] \u2026</li> </ul>"},{"location":"core/05-Inheritance/","title":"Inheritance in Python (From Simple Classes to PyTorch <code>nn.Module</code>)","text":"<p>Goal: Understand what inheritance is, see it clearly in a tiny example, and recognize (and inspect!) it inside a large framework like PyTorch.</p>"},{"location":"core/05-Inheritance/#1-what-is-inheritance","title":"1. What Is Inheritance?","text":"<p>Inheritance lets a class (the child or subclass) reuse and extend code from another class (the parent or superclass).</p> <ul> <li>Child \u201cis-a\u201d parent: <code>Dog</code> is an <code>Animal</code>.</li> <li>The child automatically gets the parent\u2019s attributes/methods unless it overrides them.</li> </ul>"},{"location":"core/05-Inheritance/#2-a-tiny-obvious-example","title":"2. A Tiny, Obvious Example","text":"<pre><code>class Animal:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return \"...\"\n\nclass Dog(Animal):  # Dog inherits from Animal\n    def speak(self):\n        return f\"{self.name} says woof!\"\n\nclass Cat(Animal):\n    def speak(self):\n        return f\"{self.name} says meow!\"\n\npets = [Dog(\"Rex\"), Cat(\"Mimi\")]\nfor p in pets:\n    print(p.speak())\n\nDog(\"Woof\").speak()\n</code></pre>"},{"location":"core/05-Inheritance/#whats-happening","title":"What\u2019s happening?","text":"<ul> <li><code>Dog(Animal)</code> and <code>Cat(Animal)</code> inherit <code>__init__</code> and <code>speak</code> (until overridden).</li> <li><code>Dog</code> and <code>Cat</code> override <code>speak()</code> to specialize behavior.</li> <li> <p>Calling <code>Dog(\"Woof\").speak()</code>:</p> </li> <li> <p>Creates a <code>Dog</code> instance.</p> </li> <li>Calls the method; Python passes the instance as <code>self</code> automatically.</li> </ul> <p>Why you can \u201csee\u201d inheritance easily here: The parent is tiny, and the child overrides a visible method (<code>speak</code>). There\u2019s no mystery\u2014everything is in one screen.</p>"},{"location":"core/05-Inheritance/#3-a-real-world-example-pytorchs-nnmodule","title":"3. A Real-World Example: PyTorch\u2019s <code>nn.Module</code>","text":"<pre><code>import torch\nfrom torch import nn\nimport inspect\n\nclass SimpleNet(nn.Module):\n    def __init__(self, in_dim, hidden, out_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden),\n            nn.ReLU(),\n            nn.Linear(hidden, out_dim)\n        )\n    def forward(self, x):\n        return self.net(x)\n\nmodel = SimpleNet(10, 32, 1)\n\n# (A) Inherited utility: count parameters\nprint(sum(p.numel() for p in model.parameters()))\n\n# (B) Inherited mode switching\nmodel.eval()\nprint(\"training flag:\", model.training)\n\n# (C) Peek at parent source\nprint(inspect.getsource(nn.Module.eval))\nprint(SimpleNet.__mro__)                     # Show inheritance chain\nprint(inspect.getsource(nn.Module.__call__)) # How forward() is invoked\n</code></pre>"},{"location":"core/05-Inheritance/#whats-being-inherited","title":"What\u2019s being inherited?","text":"<p><code>SimpleNet</code> gets a huge API from <code>nn.Module</code>, for example:</p> <ul> <li>Call flow: <code>__call__</code> (actually <code>_call_impl</code>) wraps <code>forward()</code> (hooks, autocast, etc.).</li> <li>Parameter &amp; buffer management: <code>parameters()</code>, <code>named_parameters()</code>, <code>register_parameter()</code>, <code>buffers()</code>, <code>register_buffer()</code>.</li> <li>Device/dtype moves: <code>to()</code>, <code>cpu()</code>, <code>cuda()</code>, <code>half()</code>.</li> <li>Mode switches: <code>train()</code>, <code>eval()</code>.</li> <li>Serialization: <code>state_dict()</code>, <code>load_state_dict()</code>.</li> <li>Traversal: <code>children()</code>, <code>modules()</code>, <code>named_modules()</code>.</li> </ul> <p>You only implement <code>forward()</code>. The rest is already implemented in <code>nn.Module</code>.</p> <p>Why it\u2019s harder to \u201csee\u201d inheritance here: <code>nn.Module</code> is large, and you rarely open its source. Much of the magic happens indirectly (e.g., <code>__call__</code> calls your <code>forward</code>). You rely on documentation or introspection to notice what you got \u201cfor free.\u201d</p>"},{"location":"core/05-Inheritance/#4-making-hidden-behavior-visible","title":"4. Making Hidden Behavior Visible","text":"<p>Use Python\u2019s introspection tools:</p> <pre><code>import inspect\nfrom torch import nn\n\n# Show the method resolution order (who Python looks at, and in what order)\nprint(SimpleNet.__mro__)\n\n# See how nn.Module implements __call__ and eval()\nprint(inspect.getsource(nn.Module.__call__))\nprint(inspect.getsource(nn.Module.eval))\n</code></pre> <p>Common internal call chains:</p> <ul> <li><code>model(x)</code> \u2192 <code>nn.Module.__call__(...)</code> \u2192 <code>self.forward(x)</code></li> <li><code>model.eval()</code> \u2192 <code>nn.Module.train(False)</code> \u2192 loops over children and sets flags</li> <li><code>model.to(device)</code> \u2192 <code>nn.Module._apply()</code> \u2192 moves every parameter/buffer</li> </ul>"},{"location":"core/05-Inheritance/#5-key-takeaways","title":"5. Key Takeaways","text":"<ul> <li> <p>Small demo (Animal/Dog/Cat):   Inheritance is explicit and easy to track: small parent, clear overrides.</p> </li> <li> <p>Large framework (PyTorch):   Inheritance gives you tons of functionality, but it\u2019s behind the scenes. You need to:</p> </li> <li> <p>Read docs or source.</p> </li> <li>Use <code>inspect.getsource</code>, <code>dir()</code>, <code>__mro__</code>.</li> <li> <p>Observe behavior by calling inherited methods (e.g., <code>model.parameters()</code>).</p> </li> <li> <p>Rule of thumb:   In your own code, prefer composition unless a shared interface/contract is clearly beneficial. In libraries, inheritance often standardizes that contract.</p> </li> </ul>"},{"location":"core/06-Confusion-Matrix/","title":"Confusion Matrix","text":"<p>ATTENTION: this first commit is just a pre-written code by chatgpt based on my ideas in order to have a first commit. I still need to transfer my annotations to the computer to start writing my own ideas here.</p> <p>Goal: Understand what is the confusion matrix, see all the possible metrics about it, clarify the relation between this metrics and their usefullness to day to day needs.</p>"},{"location":"core/06-Confusion-Matrix/#1-what-is-a-confusion-matrix-and-why-should-i-care","title":"1\u00a0\u00a0What is a confusion matrix and why should I care?","text":"<p>A confusion matrix is a 2\u202f\u00d7\u202f2 table that compares model predictions with ground\u2011truth labels for a binary classification task. It counts four outcomes:</p> Predicted\u00a0+ Predicted\u00a0\u2013 Actual\u00a0+ TP (True\u202fPos.) FN (False\u00a0Neg.) Actual\u00a0\u2013 FP (False\u00a0Pos.) TN (True\u202fNeg.)"},{"location":"core/06-Confusion-Matrix/#example","title":"Example","text":"<p>Suppose we test 1\u202f000 e\u2011mails (150 spam, 850 ham). The spam\u2011filter flags 120 as spam; 90 of those are real spam.</p> Pred\u202fSpam Pred\u202fHam Total Spam\u00a0(+) \u00a090\u00a0TP \u00a060\u00a0FN \u00a0150 Ham\u00a0(\u2013) \u00a030\u00a0FP \u00a0820\u00a0TN \u00a0850"},{"location":"core/06-Confusion-Matrix/#2-which-metrics-can-i-read-off-the-matrix","title":"2\u00a0\u00a0Which metrics can I read off the matrix?","text":"<p>Below each metric is phrased as the question it answers, followed by formula \u2192 value \u2192 pros\u00a0\u2223\u00a0cons using the spam example (TP\u202f=\u202f90, FP\u202f=\u202f30, FN\u202f=\u202f60, TN\u202f=\u202f820).</p>"},{"location":"core/06-Confusion-Matrix/#21-when-the-filter-shouts-spam-how-often-is-it-right-precision-ppv","title":"2.1\u00a0When the filter shouts \"spam\", how often is it right? \u2014 Precision\u00a0(PPV)","text":"<p>Formula\u2006\u00a0\u00a0$\\displaystyle \\text{TP}/(\\text{TP}+\\text{FP}) = 90/(90+30) = 0.75$ Pros\u00a0\u00a0\u2022 Trustworthiness of alerts. \u2022 Key for costly false alarms. Cons\u00a0\u00a0\u2022 Ignores misses (FN). \u2022 Drops if prevalence is low.</p>"},{"location":"core/06-Confusion-Matrix/#22-of-all-real-spam-how-much-did-we-catch-recall-sensitivity-tpr","title":"2.2\u00a0Of all real spam, how much did we catch? \u2014 Recall\u00a0(Sensitivity\u00a0\u2223\u00a0TPR)","text":"<p>Formula\u2006\u00a0\u00a0$90/(90+60)=0.60$ Pros\u00a0\u00a0\u2022 Measures coverage of positives. \u2022 Crucial in medical screening. Cons\u00a0\u00a0\u2022 Says nothing about false alarms.</p>"},{"location":"core/06-Confusion-Matrix/#23-how-do-we-balance-precision-recall-with-one-score-f1score","title":"2.3\u00a0How do we balance Precision \u2194 Recall with one score? \u2014 F\u2081\u2011Score","text":"<p>Formula\u2006\u00a0\u00a0$2PR/(P+R)=2\u00b70.75\u00b70.60/(0.75+0.60)=0.67$ Pros\u00a0\u00a0\u2022 Single knob to compare models. \u2022 Equal weight to P &amp; R. Cons\u00a0\u00a0\u2022 Hides trade\u2011offs; not interpretable probabilistically.</p>"},{"location":"core/06-Confusion-Matrix/#24-when-the-model-misses-how-bad-is-it-false-negative-rate-fnr","title":"2.4\u00a0When the model misses, how bad is it? \u2014 False\u00a0Negative\u00a0Rate\u00a0(FNR)","text":"<p>Formula\u2006\u00a0\u00a0$\\text{FN}/(\\text{FN}+\\text{TP}) = 60/150 = 0.40$ Pros\u00a0\u00a0\u2022 Directly complements Recall (FNR\u00a0=\u00a01\u2013TPR). Cons\u00a0\u00a0\u2022 Harder to reason about than Recall.</p>"},{"location":"core/06-Confusion-Matrix/#25-among-all-legitimate-mails-how-often-are-they-left-alone-true-negative-rate-specificity","title":"2.5\u00a0Among all legitimate mails, how often are they left alone? \u2014 True\u00a0Negative\u00a0Rate\u00a0(Specificity)","text":"<p>Formula\u2006\u00a0\u00a0$820/(820+30)=0.964$ Pros\u00a0\u00a0\u2022 Measures safety for negatives. \u2022 Needed for ROC curves. Cons\u00a0\u00a0\u2022 Can be misleading if negatives dominate dataset.</p>"},{"location":"core/06-Confusion-Matrix/#26-how-noisy-are-the-spam-alerts-false-positive-rate-fpr","title":"2.6\u00a0How noisy are the spam alerts? \u2014 False\u00a0Positive\u00a0Rate\u00a0(FPR)","text":"<p>Formula\u2006\u00a0\u00a0$30/(820+30)=0.036$\u00a0\u00a0\u00a0(FPR\u00a0=\u00a01\u2013Specificity) Pros\u00a0\u00a0\u2022 Axis of ROC; ties to alert budget. Cons\u00a0\u00a0\u2022 Doesn\u2019t show what was missed.</p>"},{"location":"core/06-Confusion-Matrix/#27-how-are-these-metrics-related","title":"2.7\u00a0How are these metrics related?","text":"<p>Precision\u00a0\u2248\u00a0TPR\u202f\u00b7\u202fPrevalence\u00a0/ [TPR\u202f\u00b7\u202fPrevalence\u00a0+\u00a0FPR\u202f\u00b7\u202f(1\u2013Prevalence)] \u2026and so on. Trade\u2011offs visualised via ROC or PR curves.</p>"},{"location":"core/06-Confusion-Matrix/#3-how-does-a-confusion-matrix-connect-to-bayes-rule","title":"3\u00a0\u00a0How does a confusion matrix connect to Bayes\u2019 rule?","text":"<p>Recall is the likelihood $P(\\text{Pred+}\\mid\\text{Actual+})$. Precision is the posterior $P(\\text{Actual+}\\mid\\text{Pred+})$, scaled by the prior (prevalence). Equation: $\\text{Precision}=\\dfrac{\\text{Recall}\u00b7\\text{Prevalence}}{\\text{Recall}\u00b7\\text{Prevalence}+\\text{FPR}\u00b7(1-\\text{Prevalence})}$.</p>"},{"location":"core/06-Confusion-Matrix/#example_1","title":"Example","text":"<p>Dataset prevalence\u00a0=\u00a015\u00a0%. Using spam filter\u2019s Recall\u00a0=\u00a00.60, FPR\u00a0=\u00a00.036 \u2192 Precision \u2248\u00a00.75 (matches earlier).</p> <p>Pros\u00a0\u00a0\u2022 Gives intuition about base\u2011rate fallacy. Cons\u00a0\u00a0\u2022 Needs prevalence estimate.</p>"},{"location":"core/06-Confusion-Matrix/#4-why-precision-is-so-magical","title":"4 Why precision is so magical?","text":"<ul> <li>Five ways of seeing precision</li> </ul>"},{"location":"core/06-Confusion-Matrix/#4-what-are-five-lenses-for-viewing-a-confusion-matrix","title":"4\u00a0\u00a0What are five lenses for viewing a confusion matrix?","text":"<ol> <li>Raw counts \u2014 operational impact (# of mistakes).</li> <li>Rate view \u2014 proportions (TPR, FPR).</li> <li>Bayesian view \u2014 likelihood\u00a0\u2192 posterior.</li> <li>Cost\u2011weighted \u2014 multiply cells by monetary or risk cost.</li> <li>Curve view \u2014 sweep a threshold to plot ROC / PR.</li> </ol> <p>Each lens highlights different decisions (alert limits, cost trade\u2011offs, risk appetite).</p>"},{"location":"core/06-Confusion-Matrix/#5-when-should-i-use-a-confusion-matrix-and-how-do-i-build-one","title":"5\u00a0\u00a0When should I use a confusion matrix and how do I build one?","text":"<p>When? Whenever ground truth is available for classification: medical tests, fraud flags, industrial quality control. How? In Python:</p> <pre><code>from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, y_pred, labels=[1,0])  # TP,FN,FP,TN order\n</code></pre> <p>Example pitfalls</p> <ul> <li>Class imbalance \u2192 look at rates not counts.</li> <li>Multi\u2011class \u2192 use one\u2011vs\u2011rest matrices or an $n\u00d7n$ matrix.</li> </ul> <p>Pros\u00a0\u00a0\u2022 Immediate, visual error summary. Cons\u00a0\u00a0\u2022 Needs labelled data; limited to classification.</p>"}]}